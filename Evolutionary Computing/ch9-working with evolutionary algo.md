# Working with Evolutionary Alogithms

## Important Points
- Algorithm testing must be based on many problems and many runs - good tests, good statistics 
- performance measures in general - speed - efficiency, solution quality efficacy, Robustness - sensitivity 
- Priorities in any given case can be depends on - purpose, type and budget
- scope your finding, strive for generalizable findings
- fully specify your algorithm - parameters 


## Experimentation
- has goals
- involves algorithm desing and implementation 
- needs problem to run the algorithms 
- amount to running the algo
- delivers measurement data
- evaluating the results 
- documented

## Examples
- Production prespective: Repetitive problems: similar instances with some variations in details
- Design perspective: One-off problems: “unique” requirements and conditions

## Design
- Goals 
  - desing: find a very good solution at least once
  - production: find a good solution in almost every run 
  - publication: must meet scientific standards
  - application: good enough is good enough 
- Algorithm
  - desing representation 
  - desing a way to mapp genotype to a phenotype
  - desing a way of evaluation an individual 

## Thigns to measure
- Average time
- average time for given result
- proportion of runs withitn % of target
- best resluts over n runs 
- amount of computing required 
- performance measure
  - No of generated points in the search space 
  - AES: Average number of evaluations to solutions
  - SR: success rate
  - MBF: mean best fitness 

## fair experiments
- use the same computational limit for each competitor 
